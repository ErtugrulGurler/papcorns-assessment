{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df6799dc-1fe2-4d43-bf59-c2b4dc7b1458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.99\n",
      "Confusion Matrix:\n",
      "[[127   2]\n",
      " [  1 171]]\n",
      "User #1002 (Clark Kent) churn probability: 0.01\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Set plotting style\n",
    "sns.set_theme(style=\"darkgrid\")\n",
    "sns.set_palette('deep')\n",
    "\n",
    "# Connect to the SQLite database\n",
    "conn = sqlite3.connect('papcorns.sqlite')\n",
    "\n",
    "# Load users table\n",
    "users_df = pd.read_sql_query(\"SELECT * FROM users;\", conn)\n",
    "\n",
    "# Load events table\n",
    "events_df = pd.read_sql_query(\"SELECT * FROM user_events;\", conn)\n",
    "\n",
    "\n",
    "# Preparing data again\n",
    "events_df['created_at'] = pd.to_datetime(events_df['created_at'])\n",
    "users_df['created_at'] = pd.to_datetime(users_df['created_at'])\n",
    "\n",
    "# Create the churn tag (churn = 1 if subscription_cancelled, 0 otherwise)\n",
    "events_df['churn'] = np.where(events_df['event_name'].isin(['trial_cancelled', 'subscription_cancelled']), 1, 0)\n",
    "\n",
    "\n",
    "# Calculating user features\n",
    "user_features = events_df.groupby('user_id').agg(\n",
    "    churn=('churn', 'max'),\n",
    "    days_to_subscribe=('created_at', lambda x: (x.max() - x.min()).days),\n",
    "    total_amount_paid=('amount_usd', 'sum')\n",
    ").reset_index()\n",
    "\n",
    "# Merge user information and country information\n",
    "user_features = user_features.merge(users_df[['id', 'country', 'attribution_source']], left_on='user_id', right_on='id')\n",
    "\n",
    "# One-hot encoding\n",
    "categorical_features = ['country', 'attribution_source']\n",
    "user_features = pd.get_dummies(user_features, columns=categorical_features)\n",
    "\n",
    "# Creating model\n",
    "X = user_features.drop(columns=['churn', 'user_id', 'id'])\n",
    "y = user_features['churn']\n",
    "\n",
    "# Splitting into training and test datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train the logistic regression model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predicting\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluating model accuracy and confusion matrix\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Getting Clark Kent's data\n",
    "user_1002 = users_df[users_df['id'] == 1002]\n",
    "user_1002_events = events_df[events_df['user_id'] == 1002]\n",
    "\n",
    "# Features as well\n",
    "user_1002_features = {\n",
    "    'days_to_subscribe': (user_1002_events['created_at'].max() - user_1002_events['created_at'].min()).days,\n",
    "    'total_amount_paid': user_1002_events['amount_usd'].sum(),\n",
    "    'country': user_1002['country'].values[0],\n",
    "    'attribution_source': user_1002['attribution_source'].values[0]\n",
    "}\n",
    "user_1002_features_df = pd.DataFrame([user_1002_features])\n",
    "\n",
    "\n",
    "# Get the column names of the training dataset with one-hot encoding applied\n",
    "encoded_columns = X_train.columns\n",
    "\n",
    "# When one-hot encoding user data, add the same column names\n",
    "user_1002_encoded = pd.get_dummies(user_1002_features_df, columns=['country', 'attribution_source'])\n",
    "\n",
    "# Add columns that are incompatible with the columns used in training and fill in the missing ones with 0\n",
    "user_1002_encoded = user_1002_encoded.reindex(columns=encoded_columns, fill_value=0)\n",
    "\n",
    "#Predicting\n",
    "churn_probability = model.predict_proba(user_1002_encoded)[:, 1]\n",
    "\n",
    "print(f\"User #1002 (Clark Kent) churn probability: {churn_probability[0]:.2f}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764cfd05-1af7-460e-bdf8-46d11514e60b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
